{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_file(path):\n",
    "    with open(path, 'r') as csv:\n",
    "        next(csv) # file本身就是generator\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2]) # 最后一个是换行符\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = stream_file('../data/csvfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手机 便宜   但 声音 有点 小,0\n",
      "\n",
      "手机 便宜   但 声音 有点 小\n"
     ]
    }
   ],
   "source": [
    "text, label = next(sf)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stop_words\n",
    "stopwords = open('../data/stop_words.txt', 'r', encoding='GBK').read() #打不开则用GBK编码， 默认使用utf8\n",
    "stops = stopwords.splitlines() # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def tokenizer(text):\n",
    "    try:\n",
    "        return text.split() # 以任意空格分割句子\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        global count\n",
    "        count += 1\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "vect = HashingVectorizer(decode_error='ignore', n_features=2**21, preprocessor=None, \n",
    "                         tokenizer=tokenizer, stop_words=stops)\n",
    "clf = SGDClassifier(loss='log', random_state=1, n_iter=1, class_weight={0:18, 1:1}) # 基于随机梯度下降的logistic回归模型\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(32): # 分批次，每次选取10000个进行训练\n",
    "    X_train, y_train = get_minibatch(sf, size=10000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.84319\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(sf, size=100000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(\"accuracy:{}\".format(clf.score(X_test, y_test))) # 精确度与线性模型不相上下，但速度大大提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight={0: 18, 1: 1},\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=1,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=1, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('sgdmodel0.85.pkl', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:0\n",
      "possibility:84.67%\n"
     ]
    }
   ],
   "source": [
    "with open('sgdmodel0.85.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "label = {0:'negative', 1:'positive'}\n",
    "example = ['手机 性能 很 差']\n",
    "X = vect.transform(example)\n",
    "print(\"label:%s\\npossibility:%.2f%%\" % (clf.predict(X)[0], np.max(clf.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
